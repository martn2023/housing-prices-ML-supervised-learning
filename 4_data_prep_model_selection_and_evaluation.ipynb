{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f2d4bc-7c9c-4a35-829b-ed9055f85a95",
   "metadata": {},
   "source": [
    "### Final notebook\n",
    "Unfortunately, due to difficulties later explained, this notebook crams 3 different tasks:\n",
    "##### Data preparation\n",
    "Now that we have split the data and done EDA, it's time to prepare the data for analysis. This might entail:\n",
    "1. addressing missing values\n",
    "2. trying to make numerical sense of non-numerical inputs (features)\n",
    "\n",
    "##### Model Selection\n",
    "\n",
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695db5f-3ba4-4bfe-ac39-0c38cde8d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training data into 2 buckets (1 for inputs, 1 for price outputs) so they don't pollute each other during training\n",
    "import os\n",
    "import pandas #required to convert into a DataFrame\n",
    "\n",
    "PROJECT_FILE_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "csv_path = os.path.join(PROJECT_FILE_PATH, \"stratified_training_80.csv\")\n",
    "full_stratified_training80_data = pandas.read_csv(csv_path)\n",
    "\n",
    "training80_inputs_features_df  = full_stratified_training80_data.drop(\"median_house_value\", axis=1)\n",
    "training80_prices_labels_df = full_stratified_training80_data[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465bf6f2-e66b-43a6-9251-16d733770985",
   "metadata": {},
   "source": [
    "### Checking for blank values\n",
    "I wanted a pulse check to see which dimensions are missing values and how bad is the relative damage. If the total_bedrooms had a lot of empty rows\n",
    "and those empty rows were randomly distributed, it might make sense to remove the rows with empty data. However, if I had reason to believe the empties\n",
    "showed up in a biased way (e.g. voters claiming to be undecided) AND the dimension wasn't a key feature of predicting prices, I might remove the entire\n",
    "dimension. Given the percentages shown below and the book's hint, I feel more comfortable now auto-filling blanks with the median bedroom count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fb732a-41c2-4407-9200-ebe14f9fa77b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_values_counts = training80_inputs_features_df.isnull().sum()\n",
    "missing_values_percentages = (training80_inputs_features_df.isnull().sum() / len(training80_inputs_features_df)) * 100\n",
    "\n",
    "# make a spreadsheet through pandas dataframe\n",
    "missing_values_report = pandas.DataFrame({\n",
    "    'Missing Values': missing_values_counts,\n",
    "    'Percentage (%)': missing_values_percentages\n",
    "})\n",
    "\n",
    "print(missing_values_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9656111c-b692-41e6-bf56-dad9705dc37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer # so I don't have to fill-in blanks one dimension at a time manually\n",
    "imputer_tool = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# Cloning the training DataFrame, excluding the non-numerical dimensions \"ocean_proximity\" and \"concatenated_position\"\n",
    "numerical_only_training80_df = training80_inputs_features_df.drop([\"ocean_proximity\", \"concatenated_position\", \"position_hash\"], axis=1)\n",
    "\n",
    "imputer_tool.fit(numerical_only_training80_df)\n",
    "imputed_numerical_only_training80_df = imputer_tool.transform(numerical_only_training80_df)\n",
    "imputed_numerical_only_training80_df = pandas.DataFrame(imputed_numerical_only_training80_df, columns=numerical_only_training80_df.columns)\n",
    "\n",
    "no_missing_values_verification = imputed_numerical_only_training80_df.isnull().sum()\n",
    "#print(no_missing_values_verification) #proves that blank rows are replaced, now move on to encoding non-numerical (OCEAN_PROXIMITY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ddea7-2e08-44aa-895a-b6d55a543c00",
   "metadata": {},
   "source": [
    "### Dealing with non-numerical data\n",
    "This is one-hot encoding, which converts different attributes into boolean values so we can start quantifying relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfaad47-7909-4a13-88e2-bbfba8345fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Although there were multiple non-numeric dimensions, 2 of them are trashed b/c they were for ordering/selection.\n",
    "ocean_proximity_df = training80_inputs_features_df[[\"ocean_proximity\"]] #no need for unique identifier, because row ordering is preserved between DFs\n",
    "\n",
    "encoder_tool_instance = OneHotEncoder()\n",
    "\n",
    "ocean_proximity_encoded = encoder_tool_instance.fit_transform(ocean_proximity_df)\n",
    "\n",
    "# Add details to new columns' names\n",
    "ocean_proximity_encoded_df = pandas.DataFrame(ocean_proximity_encoded.toarray(), columns=encoder_tool_instance.get_feature_names_out([\"ocean_proximity\"]))\n",
    "\n",
    "#print(ocean_proximity_encoded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f00e9e-30c6-485b-876f-1ee49fbe9e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-combine newly filled numerical data with newly one-hot encoded ocean_proximity data\n",
    "final_training80_df = pandas.concat([imputed_numerical_only_training80_df, ocean_proximity_encoded_df], axis=1)\n",
    "#final_training80_df.head() #proof 5 new columns replaced single column on ocean proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6834d89-607d-45c4-a670-c47e496cfd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An estimator leverages existing data to make predictions, and sci-kit has premade estimators\n",
    "from sklearn.base import BaseEstimator # this is the template for making fresh estimators, which might include estimator type (regressors) or classes\n",
    "from sklearn.base import TransformerMixin # a blueprint for making a new transformer that will learn from data and then modify info\n",
    "import numpy\n",
    "\n",
    "rooms_index = 3 #yes, I'm aware I could have done this in one single line like the textbook\n",
    "bedrooms_index = 4\n",
    "population_index = 5\n",
    "households_index = 6\n",
    "\n",
    "# Define the custom transformer class\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True):  # Initialize with a hyperparameter\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # This transformer doesn't need to learn anything from the data, so we just return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_index] / X[:, households_index]\n",
    "        population_per_household = X[:, population_index] / X[:, households_index]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_index] / X[:, rooms_index]\n",
    "            return numpy.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return numpy.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "#At the end of the EDA notebook, we discovered that bedrooms:total rooms ratio offered moderately predictive (inverse) value for finding house prices \n",
    "#For this reason, I am overriding the suggestion in the textbook to disable \"add_bedrooms_per_room\"\n",
    "#attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "\n",
    "# Apply the transformer to the data (assuming `housing.values` is your data)\n",
    "housing_with_extra_attribs = CombinedAttributesAdder().transform(final_training80_df.values) #see how we used the whole transformer and its defaults?\n",
    "\n",
    "# Optionally, convert the result back to a DataFrame for easier handling\n",
    "housing_extra_attribs_df = pandas.DataFrame(housing_with_extra_attribs, columns=list(final_training80_df.columns) + [\"rooms_per_household\", \"population_per_household\",\"bedrooms_per_rooms\"])\n",
    "#print(housing_extra_attribs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ddf984-0e74-4093-80e2-4330064c09e4",
   "metadata": {},
   "source": [
    "### Feature scaling\n",
    "Some models will be thrown off if dimensions use different scales, like room count going up to the thousands but income bands only hitting 15\n",
    "The solution is \"feature scaling\". We can min-max (use bottom and top of seen values, then adjust to 0-1), or standardization (find average + std dev)\n",
    "\n",
    "Standardization is supposed to be the default go-to method because most models assume certain math,\n",
    "but there are exceptions depending on data and model choice. In the real world, I'd check.\n",
    "In the interest of expediency, I'm gonna take the author's hints on faith and just assume Standardization works.\n",
    "\n",
    "I'll use SciKit's \"StandardScaler\" tool to help me eventually, but it will sit as the 3rd transformer in a 3-transformer pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119fd55-1fad-4dc8-bac3-3944bad818e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Need to dictate column headings or it will see 11, but expect 8 dimensions\n",
    "original_columns = list(numerical_only_training80_df.columns)\n",
    "added_columns = [\"rooms_per_household\", \"population_per_household\", \"bedrooms_per_room\"]\n",
    "all_columns = original_columns + added_columns\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(numerical_only_training80_df)\n",
    "\n",
    "# Need to convert to Pandas dataframe b/c previous variable is a Numpy array\n",
    "housing_num_tr_df = pandas.DataFrame(housing_num_tr, columns=all_columns)\n",
    "print(housing_num_tr_df.describe()) #all means should be close to zero and all std devs should be close to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a823313-20b9-48a8-a372-c0bcd1297f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(numerical_only_training80_df)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "\n",
    "'''\n",
    "# special section on saving pipeline for use in other notebooks (e.g. 5)\n",
    "full_pipeline.fit(final_training80_df) # need to denote final_training80_df or it won't carry over to Notebook 5 via JobLib\n",
    "full_pipeline_from_notebook4 = full_pipeline # intentionally saving the pipeline with the verbose alias\n",
    "import joblib #it was either this or Pickle\n",
    "pipeline_path = os.path.join(PROJECT_FILE_PATH, \"full_pipeline_from_notebook4.pkl\")\n",
    "joblib.dump(full_pipeline_from_notebook4, pipeline_path)\n",
    "# special section ends\n",
    "'''\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(full_stratified_training80_data)\n",
    "\n",
    "new_num_attribs = num_attribs + [\"rooms_per_household\", \"population_per_household\", \"bedrooms_per_room\"]\n",
    "full_attribs = new_num_attribs + list(full_pipeline.named_transformers_['cat'].get_feature_names_out(cat_attribs))\n",
    "\n",
    "housing_prepared_df = pandas.DataFrame(housing_prepared, columns=full_attribs)\n",
    "#print(housing_prepared_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de414b84-4a6f-43e8-81da-099cc8ffd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking back, I want to save prepared data to a CSV so I can dedicate a new notebook to training the 3 moddels\n",
    "#disregard the cells below as they are being kept as a backup until I'm 100% sure that the next notebook is self-sufficient\n",
    "\n",
    "prepared_features_csv_path = os.path.join(PROJECT_FILE_PATH, \"prepared_training80_features_only.csv\")\n",
    "separated_labels_csv_path = os.path.join(PROJECT_FILE_PATH, \"prepared_training80_labels_only.csv\")\n",
    "\n",
    "housing_prepared_df.to_csv(prepared_features_csv_path, index=False)\n",
    "print(f\"Prepared training80 FEATURES saved to {prepared_features_csv_path}\")\n",
    "\n",
    "training80_prices_labels_df.to_csv(separated_labels_csv_path, index=False)\n",
    "print(f\"Prepared training80 LABELS saved to {separated_labels_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520506b-f15f-4372-b58d-94680bfd46a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression() #take note of name as we will reuse this instance later\n",
    "lin_reg.fit(housing_prepared, training80_prices_labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e35567-6327-43e0-a4be-0d772c08081d",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "\n",
    "since this is a linear regression, think of it as Price=a×A+b×B+c×C+Intercept where\n",
    "1. lowercase a, b, c and INTERCEPT are the discovered/calculated coeffiencts\n",
    "2. uppercase A B and C are the inputs coming from features such as household income or bedrooms per room\n",
    "\n",
    "Linear Regression is favored when data is clean and the relationship between inputs and outputs is likely straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f2cfb-3c4b-4a9b-a02b-5a760ceac528",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = full_stratified_training80_data.iloc[:3]\n",
    "some_labels = training80_prices_labels_df.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared)) # predicted housing prices for the first 5 rows of data, so want to dive into the math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f50435-412e-4c7e-8ee8-890311b2e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels:\", list(some_labels)) # as a basis for comparison, these are the first 5 ACTUAL prices and 3/5 are close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44705ff3-f75e-4b2f-8ea2-feb7021b5d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = lin_reg.coef_\n",
    "intercept = lin_reg.intercept_\n",
    "\n",
    "first_row_values = some_data_prepared[0]\n",
    "\n",
    "calculated_price = numpy.dot(coefficients, first_row_values) + intercept\n",
    "\n",
    "print(f\"Intercept: {intercept}\")\n",
    "for feature, value, coef in zip(full_attribs, first_row_values, coefficients):\n",
    "    print(f\"{feature}: Value = {value}, Coefficient = {coef}, Contribution = {value * coef}\")\n",
    "print(f\"\\nCalculated Price: {calculated_price}\") # underlying math for prediction of 85K vs actual of 72K\n",
    "print(f\"Model Prediction: {lin_reg.predict([first_row_values])[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ae2c88-92bc-4e2b-8211-a4de5db1eb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "housing_predictions = lin_reg.predict(housing_prepared) # this is specific to linear regression, might rename later\n",
    "lin_mse = mean_squared_error(training80_prices_labels_df, housing_predictions)\n",
    "lin_rmse = numpy.sqrt(lin_mse)\n",
    "lin_rmse # a root mean square error of 68,000 is not impressive accuracy, especially if prices are range from 120K to 250K (basically 30%-50% off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f7e9ef-dfcd-46ec-9469-e7e961c23ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared_df, training80_prices_labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a1517-9a0a-4957-81c2-f3fae25b7b09",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "DecisionTree is kind of a like using a series of questions to drive a recommendation engine, with the computer figuring out\n",
    "How much to weigh each question or what order to ask them in.\n",
    "The more layers of questions, the more specific you can get but the higher the risk of overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8050c24-30a5-4d3f-8faf-f3dae695dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(housing_prepared_df, training80_prices_labels_df)\n",
    "\n",
    "housing_predictions = tree_reg.predict(housing_prepared_df)\n",
    "\n",
    "tree_mse = mean_squared_error(training80_prices_labels_df, housing_predictions)\n",
    "tree_rmse = numpy.sqrt(tree_mse)\n",
    "tree_rmse # you are going to see a zero, which means either the model (and data) is flawless or (the more likely) that there's an overfitting issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf7c73d-7e15-4c81-962d-3975c352f1ad",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "Due to the overfitting witnessed above and hesitation to dip into the test data, let's split the training data and do cross-validation\n",
    "To do this, the computer will chop the training data into 10 slices (a.k.a. folds) and run 10 experiments where each fold is essentially\n",
    "acting as testing data for a model trained by the other 9 folds.\n",
    "\n",
    "Therefore, we should see 10 scores after\n",
    "If we are lucky we will finaly see a mean RMSE (mean) that is above zero so we know it's not an overfitting error,\n",
    "still  under the 68K we saw in linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f838f5c-c179-4b40-9bb2-4632b0886523",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, housing_prepared_df, training80_prices_labels_df,\n",
    "scoring=\"neg_mean_squared_error\", cv=10)\n",
    "decisiontree_rmse_scores = numpy.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"CROSS VALIDATION SCORES ---------\")\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(decisiontree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff973ec1-bb07-4cd7-806c-2cf3a2ff351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for posterity, let's do cross validation on Linear Regression too\n",
    "\n",
    "scores = cross_val_score(lin_reg, housing_prepared_df, training80_prices_labels_df,\n",
    "scoring=\"neg_mean_squared_error\", cv=10)\n",
    "linearregression_rmse_scores = numpy.sqrt(-scores)\n",
    "\n",
    "display_scores(linearregression_rmse_scores)\n",
    "#FYI, textbook expected average RMSE of 69,052 so we are $51 too high. This could be explained away by randomization during preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b58e443-b843-4e64-aaf0-dda71f017c1e",
   "metadata": {},
   "source": [
    "### How to read this\n",
    "Since the mean of DecisionTree's RSME is still higher than linear regression's, we prefer the linear regression model.\n",
    "Now, let's try 3rd model: RandomForest\n",
    "\n",
    "A RandomForest, as the name suggests, is a collection of Decision Trees. This is more appropriate than Linear Regression when you have\n",
    "a bunch of complex intertwined cause-and-effects, such as an individual's occupation, religion, education, location being used to predict\n",
    "political registration. Obviously some areas are more more likely to be religious than others, and some jobs indicate a level of/lack of education.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4819ec5-cbc4-4460-a55c-b044e4cd8f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "mforest_reg.fit(housing_prepared_df, training80_prices_labels_df)\n",
    "\n",
    "# Calculate the training RMSE\n",
    "housing_predictions = forest_reg.predict(housing_prepared_df)  # Predict on training data\n",
    "randomforest_training_mse = mean_squared_error(training80_prices_labels_df, housing_predictions)\n",
    "randomforest_training_rmse = numpy.sqrt(randomforest_training_mse)\n",
    "print(\"Training RMSE:\", randomforest_training_rmse)  # Print the training RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9606ad-bbf7-46d0-bc60-08db5441fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare it vs cross-validation below\n",
    "scores = cross_val_score(forest_reg, housing_prepared_df, training80_prices_labels_df,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "randomforest_rmse_scores = numpy.sqrt(-scores)\n",
    "\n",
    "'''The cross validation RMSE is worse (higher numbers), indicating that the model works better when it's already seen the data and struggles when\n",
    "it's exposed to new data (point of cross validation).\n",
    "\n",
    "So although the cross validation figures are lower for randomforest than with linear regression, we shouldn't take it too seriously\n",
    "'''\n",
    "display_scores(randomforest_rmse_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e13416-4ccd-4e42-8af6-4b853ff68ba1",
   "metadata": {},
   "source": [
    "### Prelim results\n",
    "The preliminary training suggests that Linear Regression might be the best way to predict housing prices.\n",
    "Wouldn't it be neat if we could test out models with different parameters such as \n",
    "A) picking and ignoring x features\n",
    "B) drafting 2 vs 6 features\n",
    "C) using 2 vs 4 trees/levels in a Decision Tree\n",
    "\n",
    "Up until now, we have done Data Engineering and Data Science, but not Machine Learning\n",
    "Now, we will use ML to experiment with different permutations of hyperparameters, which are like settings, to find best configuration for the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8f884-bb70-48ae-826f-64c24c3b6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# these are the different settings/parameters\n",
    "param_grid = [\n",
    " {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    " {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    " ]\n",
    "\n",
    "'''So why are we exploring RandomForest first if Linear Regression showed more promise?\n",
    "I don't think it's not because the textbook author wanted to build suspense and save things for last.\n",
    "Maybe we're supposed to test more complicated alternative models first to see if anything, configured the right way, could compete with the\n",
    "model that's in the lead (Linear Regression)\n",
    "'''\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(housing_prepared_df, training80_prices_labels_df) #this blue box will talk about what was tried w/o commentary on what was learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd73390a-cff7-4390-988f-104bb56623a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command will tell us what the \"best\" configuration is, but it won't quantify for us what the (average) RSME is\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be541dfd-0426-43c5-8577-2383b7ad2766",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "The RandomForest worked best while looking at 6 features at most, and having 30 different trees in the forrest. Pretend that 30 authors wrote 30\n",
    "different instruction manuals for constructing a Lego tower. Each tower would look different, and we'd vote on the best-looking tower to decide which\n",
    "instruction manual (DecisionTree) was best. If we have too few, we're not precise enough in our evaluation. Too many, and we'd be\n",
    "overfitting (too specific).\n",
    "\n",
    "Counterintuitive, but it's dangerous to consider too many features because I'd be giving chances to weaker predictors a chance to dilute\n",
    "the impact of the stronger predictors. It could create white noise that the model extracts false insights/patterns from (a.k.a. overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822cb85-ebbb-432a-98b7-5cae1ec896f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cross_validation_results = grid_search.cv_results_ #cv_results is a reserved term\n",
    "\n",
    "for mean_score, params in zip(cross_validation_results[\"mean_test_score\"], cross_validation_results[\"params\"]):\n",
    "    print(numpy.sqrt(-mean_score), params)\n",
    "\n",
    "#only 1 result was under $50,000 RMSE, so the below data matches the outcome from cell above\n",
    "#Texbook predicted 49,682 and I got 49,960 which suggests this is on the right track"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a425986-80fe-462f-8a8f-331c35aac399",
   "metadata": {},
   "source": [
    "## NEW MILESTONE: FIRST ML DEMO\n",
    "\n",
    "I just used GridSearch this beginner exercise, but it worked because the complexity is limited. In the real world, there will be situations where\n",
    "the optimal number of estimators or optimal feature count is on a very wide range. In those situations, I should use RandomizedSearchCV instead. The\n",
    "author gave readers some training wheels because it's my first ML project\n",
    "\n",
    "***BTW THE ABOVE CELL MARKS THE FIRST TIME I'VE ACTUALLY LEVERAGED MACHINE-LEARNING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2dc4db-5a49-44e6-9d06-e5f2f38b177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances\n",
    "\n",
    "#Since there are 16 features, you should see 16 different scores. Next, we will sort features by value to see what we keep/toss before using test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ba08eb-55a5-42fe-a30c-0707a478ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time to evaluate those Feature Scores\n",
    "\n",
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c85e9f4-1c10-48bb-a300-bc80222ba78a",
   "metadata": {},
   "source": [
    "### Snap reactions\n",
    "As we saw in previous notebooks, median household income is the best predictor of housing prices. One might think that properties are more\n",
    "expensive on islands due to media portrayals. The reality is that island status has nearly zero correlation (see its ranking at bottom) and therefore \n",
    "nearly zero causality of prices. Was not expecting that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a015ba15-f3c7-4475-9079-da76d25a07da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the test dataset, which is missing numerical values and encoding on ocean proximity\n",
    "test_csv_path = os.path.join(PROJECT_FILE_PATH, \"stratified_testing_20.csv\")\n",
    "full_stratified_test_data = pandas.read_csv(test_csv_path)\n",
    "full_stratified_test_data.describe() # confirms only 20% of ~20,000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f32390-3a17-454f-b7c4-454f36119476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data didn't originally work due to column name inconsistencies\n",
    "X_test_prepared = pandas.DataFrame(full_pipeline.transform(X_test), columns=full_attribs)\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = numpy.sqrt(final_mse)\n",
    "print(f\"FINAL RMSE: {final_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7fdd4e-4333-4d4c-b984-dce544750c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "numpy.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "    loc=squared_errors.mean(),\n",
    "    scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3576352-84df-4f74-8eb2-f439baca1a8b",
   "metadata": {},
   "source": [
    "### RSME\n",
    "Final evaluation of test data shows an RSME of 48,468, which is is a bit worse than what the book found at 47,730\n",
    "\n",
    "### CONFIDENCE INTERVAL\n",
    "It might be more informative to give a confidence band. Said another way, if the computer is declaring 48468:\n",
    "95% of the time, truth is between 46,484 and 50,374. The wider the gap between the low vs. high, the less confident we are in the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f251a9a-86da-4dc1-979b-2d1fea9d2f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
