{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9762c321-08e5-492a-831a-a14c41405abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nTHIS NOTEBOOK'S QUESTION:\\nWhy and how will we divide these 20K rows into TRAINING (80%) vs TESTING (20%)?\\n\\nDATA LEAKAGE:\\nIf we clean the data before splitting, the eventual TESTING data will inform/bias the TRAINING data, likely making the results too clean\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "THIS NOTEBOOK'S QUESTION:\n",
    "Why and how will we divide these 20K rows into TRAINING (80%) vs TESTING (20%)?\n",
    "\n",
    "DATA LEAKAGE:\n",
    "If we clean the data before splitting, the eventual TESTING data will inform/bias the TRAINING data, likely making the results too clean\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c32061b-14e2-48e2-b00a-0145d0a23908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas #required to convert into a DataFrame\n",
    "\n",
    "PROJECT_FILE_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "csv_path = os.path.join(PROJECT_FILE_PATH, \"housing.csv\")\n",
    "housing_dataframe = pandas.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb60bc68-4dad-4b83-a8c8-758240e8899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to split the dataset in an unbiased way, we want to use randoomized hash values\n",
    "# but we want the hash values to come from a consistent source, so we are using STABLE position values from longitude/latitude\n",
    "\n",
    "housing_dataframe[\"concatenated_position\"] = (\n",
    "    housing_dataframe[\"longitude\"].astype(str) + \"_\" + housing_dataframe[\"latitude\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26638106-06cf-4e82-ae20-47a49f6f4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a hash value rooted in \"concatenated_position\"\n",
    "from zlib import crc32\n",
    "housing_dataframe[\"position_hash\"] = housing_dataframe[\"concatenated_position\"].apply(lambda x: crc32(x.encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39de0ff1-8141-489c-815c-82d61f0e605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training (80%) and testing (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_dataframe, test_dataframe = train_test_split(housing_dataframe, test_size=0.2, random_state=42) #using a common utility from scikit package\n",
    "train_dataframe.head() #this will give us a demonstration of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c21e06-393b-4916-9995-95d0d208a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = os.path.join(PROJECT_FILE_PATH, \"training80.csv\")\n",
    "test_csv_path = os.path.join(PROJECT_FILE_PATH, \"testing20.csv\")\n",
    "\n",
    "train_dataframe.to_csv(train_csv_path, index=False)\n",
    "print(f\"Training data saved to {train_csv_path}\")\n",
    "\n",
    "train_dataframe.to_csv(test_csv_path, index=False)\n",
    "print(f\"Testing data saved to {test_csv_path}\")\n",
    "\n",
    "'''\n",
    "We just verified that:\n",
    "1. the training set has 80% a.k.a. 16,512 rows\n",
    "2. the testing set has 20% a.k.a. 4,128 rows\n",
    "3. both sets were saved as CSVs in correct folder\n",
    "\n",
    "However, the downside with using that as that the computer may have weighted the data in the wrong portions expected by something like median income\n",
    "\n",
    "'''\n",
    "\n",
    "train_dataframe.describe() # write down the mean longitude here, and compare it to what you see later in stratified sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0061c-9413-4a2a-8a24-8667b6a3c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#begin stratified sampling (according to median income)\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "#creating a new \"income_cat\" for banding\n",
    "housing_dataframe[\"income_cat\"] = pandas.cut(\n",
    "    housing_dataframe[\"median_income\"],\n",
    "    bins=[0., 1.5, 3.0, 4.5, 6., numpy.inf],\n",
    "    labels=[1, 2, 3, 4, 5]\n",
    ")\n",
    "\n",
    "#display function\n",
    "housing_dataframe[\"income_cat\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd2f41-94a4-4e98-b7ad-4a2cf5b583af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42) # we only split once, test_size is a reserved term\n",
    "for train_index, test_index in split.split(housing_dataframe, housing_dataframe[\"income_cat\"]):\n",
    "    strat_train_set = housing_dataframe.loc[train_index]\n",
    "    strat_test_set = housing_dataframe.loc[test_index]\n",
    "\n",
    "strat_train_set.describe() #take note that the mean longitude differs from the 1 in non-stratified(random) sample, suggesting it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6f96fb-75ef-45ea-8102-77dc222c3cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set[\"income_cat\"].value_counts() / len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e80309c-eb1a-4605-8a20-5ecd79e9625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eyeballing this, the similarities in distribution between training vs test data shows stratification worked\n",
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46848bcc-545c-4c82-b2c3-5e8ca7ef4ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# even though .decribe doesnt show, there was an extra column used as a reference for stratification\n",
    "print(strat_train_set.columns)\n",
    "print(strat_test_set.columns)\n",
    "\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    try:\n",
    "        set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "        print(\"\\n wiped dimension: income_cat \\n\")\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "print(strat_train_set.columns)\n",
    "print(strat_test_set.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9322ea3-1cf5-48d3-99d8-e03a4ba13678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as CSVs so other notebooks can import\n",
    "strat_train_csv_path = os.path.join(PROJECT_FILE_PATH, \"stratified_training_80.csv\")\n",
    "strat_test_csv_path = os.path.join(PROJECT_FILE_PATH, \"stratified_testing_20.csv\")\n",
    "\n",
    "strat_train_set.to_csv(strat_train_csv_path, index=False)\n",
    "print(f\"Stratified training data saved to {strat_train_csv_path}\")\n",
    "\n",
    "strat_test_set.to_csv(strat_test_csv_path, index=False)\n",
    "print(f\"Stratified testing data saved to {strat_test_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050af31-a20e-4b55-8ba6-cd7f9d844acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
