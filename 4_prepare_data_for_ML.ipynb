{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d695db5f-3ba4-4bfe-ac39-0c38cde8d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training data into 2 buckets (1 for inputs, 1 for price outputs) so they don't pollute each other during training\n",
    "import os\n",
    "import pandas #required to convert into a DataFrame\n",
    "\n",
    "PROJECT_FILE_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "csv_path = os.path.join(PROJECT_FILE_PATH, \"stratified_training_80.csv\")\n",
    "full_stratified_training80_data = pandas.read_csv(csv_path)\n",
    "\n",
    "training80_inputs_features_df  = full_stratified_training80_data.drop(\"median_house_value\", axis=1)\n",
    "training80_prices_labels_df = full_stratified_training80_data[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fb732a-41c2-4407-9200-ebe14f9fa77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Missing Values  Percentage (%)\n",
      "longitude                           0         0.00000\n",
      "latitude                            0         0.00000\n",
      "housing_median_age                  0         0.00000\n",
      "total_rooms                         0         0.00000\n",
      "total_bedrooms                    158         0.95688\n",
      "population                          0         0.00000\n",
      "households                          0         0.00000\n",
      "median_income                       0         0.00000\n",
      "ocean_proximity                     0         0.00000\n",
      "concatenated_position               0         0.00000\n",
      "position_hash                       0         0.00000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "I wanted a pulse check to see which dimensions are missing values and how bad is the relative damage. If the total_bedrooms had a lot of empty rows\n",
    "and those empty rows were randomly distributed, it might make sense to remove the rows with empty data. However, if I had reason to believe the empties\n",
    "showed up in a biased way (e.g. voters claiming to be undecided) AND the dimension wasn't a key feature of predicting prices, I might remove the entire\n",
    "dimension. Given the percentages shown below and the book's hint, I feel more comfortable now auto-filling blanks with the median bedroom count.\n",
    "'''\n",
    "\n",
    "missing_values_counts = training80_inputs_features_df.isnull().sum()\n",
    "missing_values_percentages = (training80_inputs_features_df.isnull().sum() / len(training80_inputs_features_df)) * 100\n",
    "\n",
    "# make a spreadsheet through pandas dataframe\n",
    "missing_values_report = pandas.DataFrame({\n",
    "    'Missing Values': missing_values_counts,\n",
    "    'Percentage (%)': missing_values_percentages\n",
    "})\n",
    "\n",
    "print(missing_values_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9656111c-b692-41e6-bf56-dad9705dc37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude             0\n",
      "latitude              0\n",
      "housing_median_age    0\n",
      "total_rooms           0\n",
      "total_bedrooms        0\n",
      "population            0\n",
      "households            0\n",
      "median_income         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer # so I don't have to fill-in blanks one dimension at a time manually\n",
    "imputer_tool = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# Cloning the training DataFrame, excluding the non-numerical dimensions \"ocean_proximity\" and \"concatenated_position\"\n",
    "numerical_only_training80_df = training80_inputs_features_df.drop([\"ocean_proximity\", \"concatenated_position\", \"position_hash\"], axis=1)\n",
    "\n",
    "imputer_tool.fit(numerical_only_training80_df)\n",
    "imputed_numerical_only_training80_df = imputer_tool.transform(numerical_only_training80_df)\n",
    "imputed_numerical_only_training80_df = pandas.DataFrame(imputed_numerical_only_training80_df, columns=numerical_only_training80_df.columns)\n",
    "\n",
    "no_missing_values_verification = imputed_numerical_only_training80_df.isnull().sum()\n",
    "print(no_missing_values_verification) #proves that blank rows are replaced, now move on to encoding non-numerical (OCEAN_PROXIMITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfaad47-7909-4a13-88e2-bbfba8345fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ocean_proximity_<1H OCEAN  ocean_proximity_INLAND  ocean_proximity_ISLAND  \\\n",
      "0                        0.0                     1.0                     0.0   \n",
      "1                        0.0                     0.0                     0.0   \n",
      "2                        0.0                     1.0                     0.0   \n",
      "3                        0.0                     0.0                     0.0   \n",
      "4                        1.0                     0.0                     0.0   \n",
      "\n",
      "   ocean_proximity_NEAR BAY  ocean_proximity_NEAR OCEAN  \n",
      "0                       0.0                         0.0  \n",
      "1                       0.0                         1.0  \n",
      "2                       0.0                         0.0  \n",
      "3                       0.0                         1.0  \n",
      "4                       0.0                         0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Although there were multiple non-numeric dimensions, 2 of them are trashed b/c they were for ordering/selection.\n",
    "ocean_proximity_df = training80_inputs_features_df[[\"ocean_proximity\"]] #no need for unique identifier, because row ordering is preserved between DFs\n",
    "\n",
    "encoder_tool_instance = OneHotEncoder()\n",
    "\n",
    "ocean_proximity_encoded = encoder_tool_instance.fit_transform(ocean_proximity_df)\n",
    "\n",
    "# Add details to new columns' names\n",
    "ocean_proximity_encoded_df = pandas.DataFrame(ocean_proximity_encoded.toarray(), columns=encoder_tool_instance.get_feature_names_out([\"ocean_proximity\"]))\n",
    "\n",
    "print(ocean_proximity_encoded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2f00e9e-30c6-485b-876f-1ee49fbe9e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity_&lt;1H OCEAN</th>\n",
       "      <th>ocean_proximity_INLAND</th>\n",
       "      <th>ocean_proximity_ISLAND</th>\n",
       "      <th>ocean_proximity_NEAR BAY</th>\n",
       "      <th>ocean_proximity_NEAR OCEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-121.46</td>\n",
       "      <td>38.52</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3873.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>2237.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2.1736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-117.23</td>\n",
       "      <td>33.09</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>6.3373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-119.04</td>\n",
       "      <td>35.37</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.8750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-117.13</td>\n",
       "      <td>32.75</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>2.2264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-118.70</td>\n",
       "      <td>34.28</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3536.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>4.4964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -121.46     38.52                29.0       3873.0           797.0   \n",
       "1    -117.23     33.09                 7.0       5320.0           855.0   \n",
       "2    -119.04     35.37                44.0       1618.0           310.0   \n",
       "3    -117.13     32.75                24.0       1877.0           519.0   \n",
       "4    -118.70     34.28                27.0       3536.0           646.0   \n",
       "\n",
       "   population  households  median_income  ocean_proximity_<1H OCEAN  \\\n",
       "0      2237.0       706.0         2.1736                        0.0   \n",
       "1      2015.0       768.0         6.3373                        0.0   \n",
       "2       667.0       300.0         2.8750                        0.0   \n",
       "3       898.0       483.0         2.2264                        0.0   \n",
       "4      1837.0       580.0         4.4964                        1.0   \n",
       "\n",
       "   ocean_proximity_INLAND  ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n",
       "0                     1.0                     0.0                       0.0   \n",
       "1                     0.0                     0.0                       0.0   \n",
       "2                     1.0                     0.0                       0.0   \n",
       "3                     0.0                     0.0                       0.0   \n",
       "4                     0.0                     0.0                       0.0   \n",
       "\n",
       "   ocean_proximity_NEAR OCEAN  \n",
       "0                         0.0  \n",
       "1                         1.0  \n",
       "2                         0.0  \n",
       "3                         1.0  \n",
       "4                         0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-combine newly filled numerical data with newly one-hot encoded ocean_proximity data\n",
    "final_training80_df = pandas.concat([imputed_numerical_only_training80_df, ocean_proximity_encoded_df], axis=1)\n",
    "final_training80_df.head() #proof 5 new columns replaced single column on ocean proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6834d89-607d-45c4-a670-c47e496cfd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -121.46     38.52                29.0       3873.0           797.0   \n",
      "1    -117.23     33.09                 7.0       5320.0           855.0   \n",
      "2    -119.04     35.37                44.0       1618.0           310.0   \n",
      "3    -117.13     32.75                24.0       1877.0           519.0   \n",
      "4    -118.70     34.28                27.0       3536.0           646.0   \n",
      "\n",
      "   population  households  median_income  ocean_proximity_<1H OCEAN  \\\n",
      "0      2237.0       706.0         2.1736                        0.0   \n",
      "1      2015.0       768.0         6.3373                        0.0   \n",
      "2       667.0       300.0         2.8750                        0.0   \n",
      "3       898.0       483.0         2.2264                        0.0   \n",
      "4      1837.0       580.0         4.4964                        1.0   \n",
      "\n",
      "   ocean_proximity_INLAND  ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n",
      "0                     1.0                     0.0                       0.0   \n",
      "1                     0.0                     0.0                       0.0   \n",
      "2                     1.0                     0.0                       0.0   \n",
      "3                     0.0                     0.0                       0.0   \n",
      "4                     0.0                     0.0                       0.0   \n",
      "\n",
      "   ocean_proximity_NEAR OCEAN  rooms_per_household  population_per_household  \\\n",
      "0                         0.0             5.485836                  3.168555   \n",
      "1                         1.0             6.927083                  2.623698   \n",
      "2                         0.0             5.393333                  2.223333   \n",
      "3                         1.0             3.886128                  1.859213   \n",
      "4                         0.0             6.096552                  3.167241   \n",
      "\n",
      "   bedrooms_per_rooms  \n",
      "0            0.205784  \n",
      "1            0.160714  \n",
      "2            0.191595  \n",
      "3            0.276505  \n",
      "4            0.182692  \n"
     ]
    }
   ],
   "source": [
    "#An estimator leverages existing data to make predictions, and sci-kit has premade estimators\n",
    "from sklearn.base import BaseEstimator # this is the template for making fresh estimators, which might include estimator type (regressors) or classes\n",
    "from sklearn.base import TransformerMixin # a blueprint for making a new transformer that will learn from data and then modify info\n",
    "import numpy\n",
    "\n",
    "rooms_index = 3 #yes, I'm aware I could have done this in one single line like the textbook\n",
    "bedrooms_index = 4\n",
    "population_index = 5\n",
    "households_index = 6\n",
    "\n",
    "# Define the custom transformer class\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True):  # Initialize with a hyperparameter\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # This transformer doesn't need to learn anything from the data, so we just return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_index] / X[:, households_index]\n",
    "        population_per_household = X[:, population_index] / X[:, households_index]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_index] / X[:, rooms_index]\n",
    "            return numpy.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return numpy.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "#At the end of the EDA notebook, we discovered that bedrooms:total rooms ratio offered moderately predictive (inverse) value for finding house prices \n",
    "#For this reason, I am overriding the suggestion in the textbook to disable \"add_bedrooms_per_room\"\n",
    "#attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "\n",
    "# Apply the transformer to the data (assuming `housing.values` is your data)\n",
    "housing_with_extra_attribs = CombinedAttributesAdder().transform(final_training80_df.values) #see how we used the whole transformer and its defaults?\n",
    "\n",
    "# Optionally, convert the result back to a DataFrame for easier handling\n",
    "housing_extra_attribs_df = pandas.DataFrame(housing_with_extra_attribs, columns=list(final_training80_df.columns) + [\"rooms_per_household\", \"population_per_household\",\"bedrooms_per_rooms\"])\n",
    "\n",
    "print(housing_extra_attribs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119fd55-1fad-4dc8-bac3-3944bad818e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
