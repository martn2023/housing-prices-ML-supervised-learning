{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d695db5f-3ba4-4bfe-ac39-0c38cde8d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training data into 2 buckets (1 for inputs, 1 for price outputs) so they don't pollute each other during training\n",
    "import os\n",
    "import pandas #required to convert into a DataFrame\n",
    "\n",
    "PROJECT_FILE_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "csv_path = os.path.join(PROJECT_FILE_PATH, \"stratified_training_80.csv\")\n",
    "full_stratified_training80_data = pandas.read_csv(csv_path)\n",
    "\n",
    "training80_inputs_features_df  = full_stratified_training80_data.drop(\"median_house_value\", axis=1)\n",
    "training80_prices_labels_df = full_stratified_training80_data[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fb732a-41c2-4407-9200-ebe14f9fa77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Missing Values  Percentage (%)\n",
      "longitude                           0         0.00000\n",
      "latitude                            0         0.00000\n",
      "housing_median_age                  0         0.00000\n",
      "total_rooms                         0         0.00000\n",
      "total_bedrooms                    158         0.95688\n",
      "population                          0         0.00000\n",
      "households                          0         0.00000\n",
      "median_income                       0         0.00000\n",
      "ocean_proximity                     0         0.00000\n",
      "concatenated_position               0         0.00000\n",
      "position_hash                       0         0.00000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "I wanted a pulse check to see which dimensions are missing values and how bad is the relative damage. If the total_bedrooms had a lot of empty rows\n",
    "and those empty rows were randomly distributed, it might make sense to remove the rows with empty data. However, if I had reason to believe the empties\n",
    "showed up in a biased way (e.g. voters claiming to be undecided) AND the dimension wasn't a key feature of predicting prices, I might remove the entire\n",
    "dimension. Given the percentages shown below and the book's hint, I feel more comfortable now auto-filling blanks with the median bedroom count.\n",
    "'''\n",
    "\n",
    "missing_values_counts = training80_inputs_features_df.isnull().sum()\n",
    "missing_values_percentages = (training80_inputs_features_df.isnull().sum() / len(training80_inputs_features_df)) * 100\n",
    "\n",
    "# make a spreadsheet through pandas dataframe\n",
    "missing_values_report = pandas.DataFrame({\n",
    "    'Missing Values': missing_values_counts,\n",
    "    'Percentage (%)': missing_values_percentages\n",
    "})\n",
    "\n",
    "print(missing_values_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9656111c-b692-41e6-bf56-dad9705dc37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude             0\n",
      "latitude              0\n",
      "housing_median_age    0\n",
      "total_rooms           0\n",
      "total_bedrooms        0\n",
      "population            0\n",
      "households            0\n",
      "median_income         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer # so I don't have to fill-in blanks one dimension at a time manually\n",
    "imputer_tool = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# Cloning the training DataFrame, excluding the non-numerical dimensions \"ocean_proximity\" and \"concatenated_position\"\n",
    "numerical_only_training80_df = training80_inputs_features_df.drop([\"ocean_proximity\", \"concatenated_position\", \"position_hash\"], axis=1)\n",
    "\n",
    "imputer_tool.fit(numerical_only_training80_df)\n",
    "imputed_numerical_only_training80_df = imputer_tool.transform(numerical_only_training80_df)\n",
    "imputed_numerical_only_training80_df = pandas.DataFrame(imputed_numerical_only_training80_df, columns=numerical_only_training80_df.columns)\n",
    "\n",
    "no_missing_values_verification = imputed_numerical_only_training80_df.isnull().sum()\n",
    "print(no_missing_values_verification) #proves that blank rows are replaced, now move on to encoding non-numerical (OCEAN_PROXIMITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbfaad47-7909-4a13-88e2-bbfba8345fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ocean_proximity_<1H OCEAN  ocean_proximity_INLAND  ocean_proximity_ISLAND  \\\n",
      "0                        0.0                     1.0                     0.0   \n",
      "1                        0.0                     0.0                     0.0   \n",
      "2                        0.0                     1.0                     0.0   \n",
      "3                        0.0                     0.0                     0.0   \n",
      "4                        1.0                     0.0                     0.0   \n",
      "\n",
      "   ocean_proximity_NEAR BAY  ocean_proximity_NEAR OCEAN  \n",
      "0                       0.0                         0.0  \n",
      "1                       0.0                         1.0  \n",
      "2                       0.0                         0.0  \n",
      "3                       0.0                         1.0  \n",
      "4                       0.0                         0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Although there were multiple non-numeric dimensions, 2 of them are trashed b/c they were for ordering/selection.\n",
    "ocean_proximity_df = training80_inputs_features_df[[\"ocean_proximity\"]] #no need for unique identifier, because row ordering is preserved between DFs\n",
    "\n",
    "encoder_tool_instance = OneHotEncoder()\n",
    "\n",
    "ocean_proximity_encoded = encoder_tool_instance.fit_transform(ocean_proximity_df)\n",
    "\n",
    "# Add details to new columns' names\n",
    "ocean_proximity_encoded_df = pandas.DataFrame(ocean_proximity_encoded.toarray(), columns=encoder_tool_instance.get_feature_names_out([\"ocean_proximity\"]))\n",
    "\n",
    "print(ocean_proximity_encoded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2f00e9e-30c6-485b-876f-1ee49fbe9e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity_&lt;1H OCEAN</th>\n",
       "      <th>ocean_proximity_INLAND</th>\n",
       "      <th>ocean_proximity_ISLAND</th>\n",
       "      <th>ocean_proximity_NEAR BAY</th>\n",
       "      <th>ocean_proximity_NEAR OCEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-121.46</td>\n",
       "      <td>38.52</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3873.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>2237.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2.1736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-117.23</td>\n",
       "      <td>33.09</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>6.3373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-119.04</td>\n",
       "      <td>35.37</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.8750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-117.13</td>\n",
       "      <td>32.75</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>2.2264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-118.70</td>\n",
       "      <td>34.28</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3536.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>4.4964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -121.46     38.52                29.0       3873.0           797.0   \n",
       "1    -117.23     33.09                 7.0       5320.0           855.0   \n",
       "2    -119.04     35.37                44.0       1618.0           310.0   \n",
       "3    -117.13     32.75                24.0       1877.0           519.0   \n",
       "4    -118.70     34.28                27.0       3536.0           646.0   \n",
       "\n",
       "   population  households  median_income  ocean_proximity_<1H OCEAN  \\\n",
       "0      2237.0       706.0         2.1736                        0.0   \n",
       "1      2015.0       768.0         6.3373                        0.0   \n",
       "2       667.0       300.0         2.8750                        0.0   \n",
       "3       898.0       483.0         2.2264                        0.0   \n",
       "4      1837.0       580.0         4.4964                        1.0   \n",
       "\n",
       "   ocean_proximity_INLAND  ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n",
       "0                     1.0                     0.0                       0.0   \n",
       "1                     0.0                     0.0                       0.0   \n",
       "2                     1.0                     0.0                       0.0   \n",
       "3                     0.0                     0.0                       0.0   \n",
       "4                     0.0                     0.0                       0.0   \n",
       "\n",
       "   ocean_proximity_NEAR OCEAN  \n",
       "0                         0.0  \n",
       "1                         1.0  \n",
       "2                         0.0  \n",
       "3                         1.0  \n",
       "4                         0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-combine newly filled numerical data with newly one-hot encoded ocean_proximity data\n",
    "final_training80_df = pandas.concat([imputed_numerical_only_training80_df, ocean_proximity_encoded_df], axis=1)\n",
    "final_training80_df.head() #proof 5 new columns replaced single column on ocean proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6834d89-607d-45c4-a670-c47e496cfd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -121.46     38.52                29.0       3873.0           797.0   \n",
      "1    -117.23     33.09                 7.0       5320.0           855.0   \n",
      "2    -119.04     35.37                44.0       1618.0           310.0   \n",
      "3    -117.13     32.75                24.0       1877.0           519.0   \n",
      "4    -118.70     34.28                27.0       3536.0           646.0   \n",
      "\n",
      "   population  households  median_income  ocean_proximity_<1H OCEAN  \\\n",
      "0      2237.0       706.0         2.1736                        0.0   \n",
      "1      2015.0       768.0         6.3373                        0.0   \n",
      "2       667.0       300.0         2.8750                        0.0   \n",
      "3       898.0       483.0         2.2264                        0.0   \n",
      "4      1837.0       580.0         4.4964                        1.0   \n",
      "\n",
      "   ocean_proximity_INLAND  ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n",
      "0                     1.0                     0.0                       0.0   \n",
      "1                     0.0                     0.0                       0.0   \n",
      "2                     1.0                     0.0                       0.0   \n",
      "3                     0.0                     0.0                       0.0   \n",
      "4                     0.0                     0.0                       0.0   \n",
      "\n",
      "   ocean_proximity_NEAR OCEAN  rooms_per_household  population_per_household  \\\n",
      "0                         0.0             5.485836                  3.168555   \n",
      "1                         1.0             6.927083                  2.623698   \n",
      "2                         0.0             5.393333                  2.223333   \n",
      "3                         1.0             3.886128                  1.859213   \n",
      "4                         0.0             6.096552                  3.167241   \n",
      "\n",
      "   bedrooms_per_rooms  \n",
      "0            0.205784  \n",
      "1            0.160714  \n",
      "2            0.191595  \n",
      "3            0.276505  \n",
      "4            0.182692  \n"
     ]
    }
   ],
   "source": [
    "#An estimator leverages existing data to make predictions, and sci-kit has premade estimators\n",
    "from sklearn.base import BaseEstimator # this is the template for making fresh estimators, which might include estimator type (regressors) or classes\n",
    "from sklearn.base import TransformerMixin # a blueprint for making a new transformer that will learn from data and then modify info\n",
    "import numpy\n",
    "\n",
    "rooms_index = 3 #yes, I'm aware I could have done this in one single line like the textbook\n",
    "bedrooms_index = 4\n",
    "population_index = 5\n",
    "households_index = 6\n",
    "\n",
    "# Define the custom transformer class\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True):  # Initialize with a hyperparameter\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # This transformer doesn't need to learn anything from the data, so we just return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_index] / X[:, households_index]\n",
    "        population_per_household = X[:, population_index] / X[:, households_index]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_index] / X[:, rooms_index]\n",
    "            return numpy.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return numpy.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "#At the end of the EDA notebook, we discovered that bedrooms:total rooms ratio offered moderately predictive (inverse) value for finding house prices \n",
    "#For this reason, I am overriding the suggestion in the textbook to disable \"add_bedrooms_per_room\"\n",
    "#attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "\n",
    "# Apply the transformer to the data (assuming `housing.values` is your data)\n",
    "housing_with_extra_attribs = CombinedAttributesAdder().transform(final_training80_df.values) #see how we used the whole transformer and its defaults?\n",
    "\n",
    "# Optionally, convert the result back to a DataFrame for easier handling\n",
    "housing_extra_attribs_df = pandas.DataFrame(housing_with_extra_attribs, columns=list(final_training80_df.columns) + [\"rooms_per_household\", \"population_per_household\",\"bedrooms_per_rooms\"])\n",
    "\n",
    "print(housing_extra_attribs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3119fd55-1fad-4dc8-bac3-3944bad818e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count  1.651200e+04  1.651200e+04        1.651200e+04  1.651200e+04   \n",
      "mean  -5.249246e-15  2.811597e-16        8.778508e-17 -1.549148e-17   \n",
      "std    1.000030e+00  1.000030e+00        1.000030e+00  1.000030e+00   \n",
      "min   -2.385075e+00 -1.449702e+00       -2.199176e+00 -1.223624e+00   \n",
      "25%   -1.111200e+00 -7.948529e-01       -8.472270e-01 -5.516115e-01   \n",
      "50%    5.323472e-01 -6.451732e-01        2.756357e-02 -2.354803e-01   \n",
      "75%    7.821265e-01  9.732389e-01        6.637749e-01  2.424578e-01   \n",
      "max    2.630493e+00  2.951818e+00        1.856671e+00  1.716156e+01   \n",
      "\n",
      "       total_bedrooms    population    households  median_income  \\\n",
      "count    1.651200e+04  1.651200e+04  1.651200e+04   1.651200e+04   \n",
      "mean    -1.358732e-16  6.454785e-19 -1.054282e-17   1.148414e-16   \n",
      "std      1.000030e+00  1.000030e+00  1.000030e+00   1.000030e+00   \n",
      "min     -1.294906e+00 -1.269855e+00 -1.317625e+00  -1.772289e+00   \n",
      "25%     -5.792186e-01 -5.698016e-01 -5.803051e-01  -6.871505e-01   \n",
      "50%     -2.457180e-01 -2.291867e-01 -2.369322e-01  -1.755153e-01   \n",
      "75%      2.606187e-01  2.682904e-01  2.794582e-01   4.564298e-01   \n",
      "max      1.381730e+01  3.071120e+01  1.293901e+01   5.839873e+00   \n",
      "\n",
      "       rooms_per_household  population_per_household  bedrooms_per_room  \n",
      "count         1.651200e+04              1.651200e+04       1.651200e+04  \n",
      "mean         -6.949652e-17             -2.760765e-17       5.732925e-16  \n",
      "std           1.000030e+00              1.000030e+00       1.000030e+00  \n",
      "min          -1.650308e+00             -2.075331e-01      -2.704506e+00  \n",
      "25%          -3.822298e-01             -5.741455e-02      -5.914140e-01  \n",
      "50%          -7.966877e-02             -2.406740e-02      -1.630121e-01  \n",
      "75%           2.358519e-01              1.596537e-02       4.044631e-01  \n",
      "max           5.225448e+01              1.070603e+02       3.975987e+01  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Some models will be thrown off if dimensions use different scales, like room count going up to the thousands but income bands only hitting 15\n",
    "The solution is \"feature scaling\". We can min-max (use bottom and top of seen values, then adjust to 0-1), or standardization (find average + std dev)\n",
    "\n",
    "Standardization is supposed to be the default go-to method because most models assume certain math,\n",
    "but there are exceptions depending on data and model choice. In the real world, I'd check.\n",
    "In the interest of expediency, I'm gonna take the author's hints on faith and just assume Standardization works.\n",
    "\n",
    "I'll use SciKit's \"StandardScaler\" tool to help me eventually, but it will sit as the 3rd transformer in a 3-transformer pipeline\n",
    "'''\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "'''\n",
    "although 2/3 of the below transformations were already done manually, making a reusable pipeline in preparation to call them again later,\n",
    "most likely when I'm testing 3 competing models in fine-tuning stage\n",
    "'''\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# Need to dictate column headings or it will see 11, but expect 8 dimensions\n",
    "original_columns = list(numerical_only_training80_df.columns)\n",
    "added_columns = [\"rooms_per_household\", \"population_per_household\", \"bedrooms_per_room\"]\n",
    "all_columns = original_columns + added_columns\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(numerical_only_training80_df)\n",
    "\n",
    "# Need to convert to Pandas dataframe b/c previous variable is a Numpy array\n",
    "housing_num_tr_df = pandas.DataFrame(housing_num_tr, columns=all_columns)\n",
    "print(housing_num_tr_df.describe()) #all means should be close to zero and all std devs should be close to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a823313-20b9-48a8-a372-c0bcd1297f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count  1.651200e+04  1.651200e+04        1.651200e+04  1.651200e+04   \n",
      "mean  -5.249246e-15  2.811597e-16        8.778508e-17 -1.549148e-17   \n",
      "std    1.000030e+00  1.000030e+00        1.000030e+00  1.000030e+00   \n",
      "min   -2.385075e+00 -1.449702e+00       -2.199176e+00 -1.223624e+00   \n",
      "25%   -1.111200e+00 -7.948529e-01       -8.472270e-01 -5.516115e-01   \n",
      "50%    5.323472e-01 -6.451732e-01        2.756357e-02 -2.354803e-01   \n",
      "75%    7.821265e-01  9.732389e-01        6.637749e-01  2.424578e-01   \n",
      "max    2.630493e+00  2.951818e+00        1.856671e+00  1.716156e+01   \n",
      "\n",
      "       total_bedrooms    population    households  median_income  \\\n",
      "count    1.651200e+04  1.651200e+04  1.651200e+04   1.651200e+04   \n",
      "mean    -1.358732e-16  6.454785e-19 -1.054282e-17   1.148414e-16   \n",
      "std      1.000030e+00  1.000030e+00  1.000030e+00   1.000030e+00   \n",
      "min     -1.294906e+00 -1.269855e+00 -1.317625e+00  -1.772289e+00   \n",
      "25%     -5.792186e-01 -5.698016e-01 -5.803051e-01  -6.871505e-01   \n",
      "50%     -2.457180e-01 -2.291867e-01 -2.369322e-01  -1.755153e-01   \n",
      "75%      2.606187e-01  2.682904e-01  2.794582e-01   4.564298e-01   \n",
      "max      1.381730e+01  3.071120e+01  1.293901e+01   5.839873e+00   \n",
      "\n",
      "       rooms_per_household  population_per_household  bedrooms_per_room  \\\n",
      "count         1.651200e+04              1.651200e+04       1.651200e+04   \n",
      "mean         -6.949652e-17             -2.760765e-17       5.732925e-16   \n",
      "std           1.000030e+00              1.000030e+00       1.000030e+00   \n",
      "min          -1.650308e+00             -2.075331e-01      -2.704506e+00   \n",
      "25%          -3.822298e-01             -5.741455e-02      -5.914140e-01   \n",
      "50%          -7.966877e-02             -2.406740e-02      -1.630121e-01   \n",
      "75%           2.358519e-01              1.596537e-02       4.044631e-01   \n",
      "max           5.225448e+01              1.070603e+02       3.975987e+01   \n",
      "\n",
      "       ocean_proximity_<1H OCEAN  ocean_proximity_INLAND  \\\n",
      "count               16512.000000            16512.000000   \n",
      "mean                    0.440710                0.318677   \n",
      "std                     0.496487                0.465978   \n",
      "min                     0.000000                0.000000   \n",
      "25%                     0.000000                0.000000   \n",
      "50%                     0.000000                0.000000   \n",
      "75%                     1.000000                1.000000   \n",
      "max                     1.000000                1.000000   \n",
      "\n",
      "       ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n",
      "count            16512.000000              16512.000000   \n",
      "mean                 0.000121                  0.111858   \n",
      "std                  0.011005                  0.315201   \n",
      "min                  0.000000                  0.000000   \n",
      "25%                  0.000000                  0.000000   \n",
      "50%                  0.000000                  0.000000   \n",
      "75%                  0.000000                  0.000000   \n",
      "max                  1.000000                  1.000000   \n",
      "\n",
      "       ocean_proximity_NEAR OCEAN  \n",
      "count                16512.000000  \n",
      "mean                     0.128634  \n",
      "std                      0.334804  \n",
      "min                      0.000000  \n",
      "25%                      0.000000  \n",
      "50%                      0.000000  \n",
      "75%                      0.000000  \n",
      "max                      1.000000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(numerical_only_training80_df)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(full_stratified_training80_data)\n",
    "\n",
    "new_num_attribs = num_attribs + [\"rooms_per_household\", \"population_per_household\", \"bedrooms_per_room\"]\n",
    "full_attribs = new_num_attribs + list(full_pipeline.named_transformers_['cat'].get_feature_names_out(cat_attribs))\n",
    "\n",
    "housing_prepared_df = pandas.DataFrame(housing_prepared, columns=full_attribs)\n",
    "print(housing_prepared_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520506b-f15f-4372-b58d-94680bfd46a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
