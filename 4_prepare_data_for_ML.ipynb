{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d695db5f-3ba4-4bfe-ac39-0c38cde8d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting training data into 2 buckets (1 for inputs, 1 for price outputs) so they don't pollute each other during training\n",
    "import os\n",
    "import pandas #required to convert into a DataFrame\n",
    "\n",
    "PROJECT_FILE_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "csv_path = os.path.join(PROJECT_FILE_PATH, \"stratified_training_80.csv\")\n",
    "full_stratified_training80_data = pandas.read_csv(csv_path)\n",
    "\n",
    "training80_inputs_features_df  = full_stratified_training80_data.drop(\"median_house_value\", axis=1)\n",
    "training80_prices_labels_df = full_stratified_training80_data[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fb732a-41c2-4407-9200-ebe14f9fa77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Missing Values  Percentage (%)\n",
      "longitude                           0         0.00000\n",
      "latitude                            0         0.00000\n",
      "housing_median_age                  0         0.00000\n",
      "total_rooms                         0         0.00000\n",
      "total_bedrooms                    158         0.95688\n",
      "population                          0         0.00000\n",
      "households                          0         0.00000\n",
      "median_income                       0         0.00000\n",
      "ocean_proximity                     0         0.00000\n",
      "concatenated_position               0         0.00000\n",
      "position_hash                       0         0.00000\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "I wanted a pulse check to see which dimensions are missing values and how bad is the relative damage. If the total_bedrooms had a lot of empty rows\n",
    "and those empty rows were randomly distributed, it might make sense to remove the rows with empty data. However, if I had reason to believe the empties\n",
    "showed up in a biased way (e.g. voters claiming to be undecided) AND the dimension wasn't a key feature of predicting prices, I might remove the entire\n",
    "dimension. Given the percentages shown below and the book's hint, I feel more comfortable now auto-filling blanks with the median bedroom count.\n",
    "'''\n",
    "\n",
    "missing_values_counts = training80_inputs_features_df.isnull().sum()\n",
    "missing_values_percentages = (training80_inputs_features_df.isnull().sum() / len(training80_inputs_features_df)) * 100\n",
    "\n",
    "# make a spreadsheet through pandas dataframe\n",
    "missing_values_report = pandas.DataFrame({\n",
    "    'Missing Values': missing_values_counts,\n",
    "    'Percentage (%)': missing_values_percentages\n",
    "})\n",
    "\n",
    "print(missing_values_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9656111c-b692-41e6-bf56-dad9705dc37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude             0\n",
      "latitude              0\n",
      "housing_median_age    0\n",
      "total_rooms           0\n",
      "total_bedrooms        0\n",
      "population            0\n",
      "households            0\n",
      "median_income         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer # so I don't have to fill-in blanks one dimension at a time manually\n",
    "imputer_tool = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# Cloning the training DataFrame, excluding the non-numerical dimensions \"ocean_proximity\" and \"concatenated_position\"\n",
    "numerical_only_training80_df = training80_inputs_features_df.drop([\"ocean_proximity\", \"concatenated_position\", \"position_hash\"], axis=1)\n",
    "\n",
    "imputer_tool.fit(numerical_only_training80_df)\n",
    "imputed_numerical_only_training80_df = imputer_tool.transform(numerical_only_training80_df)\n",
    "imputed_numerical_only_training80_df = pandas.DataFrame(imputed_numerical_only_training80_df, columns=numerical_only_training80_df.columns)\n",
    "\n",
    "no_missing_values_verification = imputed_numerical_only_training80_df.isnull().sum()\n",
    "print(no_missing_values_verification) #proves that blank rows are replaced, now move on to encoding non-numerical (OCEAN_PROXIMITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbfaad47-7909-4a13-88e2-bbfba8345fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ocean_proximity_<1H OCEAN  ocean_proximity_INLAND  ocean_proximity_ISLAND  \\\n",
      "0                        0.0                     1.0                     0.0   \n",
      "1                        0.0                     0.0                     0.0   \n",
      "2                        0.0                     1.0                     0.0   \n",
      "3                        0.0                     0.0                     0.0   \n",
      "4                        1.0                     0.0                     0.0   \n",
      "\n",
      "   ocean_proximity_NEAR BAY  ocean_proximity_NEAR OCEAN  \n",
      "0                       0.0                         0.0  \n",
      "1                       0.0                         1.0  \n",
      "2                       0.0                         0.0  \n",
      "3                       0.0                         1.0  \n",
      "4                       0.0                         0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Although there were multiple non-numeric dimensions, 2 of them are trashed b/c they were for ordering/selection.\n",
    "ocean_proximity_df = training80_inputs_features_df[[\"ocean_proximity\"]] #no need for unique identifier, because row ordering is preserved between DFs\n",
    "\n",
    "encoder_tool_instance = OneHotEncoder()\n",
    "\n",
    "ocean_proximity_encoded = encoder_tool_instance.fit_transform(ocean_proximity_df)\n",
    "\n",
    "# Add details to new columns' names\n",
    "ocean_proximity_encoded_df = pandas.DataFrame(ocean_proximity_encoded.toarray(), columns=encoder_tool_instance.get_feature_names_out([\"ocean_proximity\"]))\n",
    "\n",
    "print(ocean_proximity_encoded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2f00e9e-30c6-485b-876f-1ee49fbe9e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity_&lt;1H OCEAN</th>\n",
       "      <th>ocean_proximity_INLAND</th>\n",
       "      <th>ocean_proximity_ISLAND</th>\n",
       "      <th>ocean_proximity_NEAR BAY</th>\n",
       "      <th>ocean_proximity_NEAR OCEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-121.46</td>\n",
       "      <td>38.52</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3873.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>2237.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2.1736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-117.23</td>\n",
       "      <td>33.09</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5320.0</td>\n",
       "      <td>855.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>6.3373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-119.04</td>\n",
       "      <td>35.37</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1618.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2.8750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-117.13</td>\n",
       "      <td>32.75</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1877.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>2.2264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-118.70</td>\n",
       "      <td>34.28</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3536.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>4.4964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -121.46     38.52                29.0       3873.0           797.0   \n",
       "1    -117.23     33.09                 7.0       5320.0           855.0   \n",
       "2    -119.04     35.37                44.0       1618.0           310.0   \n",
       "3    -117.13     32.75                24.0       1877.0           519.0   \n",
       "4    -118.70     34.28                27.0       3536.0           646.0   \n",
       "\n",
       "   population  households  median_income  ocean_proximity_<1H OCEAN  \\\n",
       "0      2237.0       706.0         2.1736                        0.0   \n",
       "1      2015.0       768.0         6.3373                        0.0   \n",
       "2       667.0       300.0         2.8750                        0.0   \n",
       "3       898.0       483.0         2.2264                        0.0   \n",
       "4      1837.0       580.0         4.4964                        1.0   \n",
       "\n",
       "   ocean_proximity_INLAND  ocean_proximity_ISLAND  ocean_proximity_NEAR BAY  \\\n",
       "0                     1.0                     0.0                       0.0   \n",
       "1                     0.0                     0.0                       0.0   \n",
       "2                     1.0                     0.0                       0.0   \n",
       "3                     0.0                     0.0                       0.0   \n",
       "4                     0.0                     0.0                       0.0   \n",
       "\n",
       "   ocean_proximity_NEAR OCEAN  \n",
       "0                         0.0  \n",
       "1                         1.0  \n",
       "2                         0.0  \n",
       "3                         1.0  \n",
       "4                         0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-combine newly filled numerical data with newly one-hot encoded ocean_proximity data\n",
    "final_training80_df = pandas.concat([imputed_numerical_only_training80_df, ocean_proximity_encoded_df], axis=1)\n",
    "final_training80_df.head() #proof 5 new columns replaced single column on ocean proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6834d89-607d-45c4-a670-c47e496cfd19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
